{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25f77438",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page 1...\n",
      "Scraping page 2...\n",
      "Scraping page 3...\n",
      "Scraping page 4...\n",
      "Scraping page 5...\n",
      "Scraping page 6...\n",
      "Scraping page 7...\n",
      "Scraping page 8...\n",
      "Scraping page 9...\n",
      "Scraping page 10...\n",
      "Scraping page 11...\n",
      "Scraping page 12...\n",
      "Scraping page 13...\n",
      "Scraping page 14...\n",
      "Scraping page 15...\n",
      "Scraping page 16...\n",
      "Scraping page 17...\n",
      "Scraping page 18...\n",
      "Scraping page 19...\n",
      "Scraping page 20...\n",
      "Scraping completed! Data saved to mobilemisr_phones.csv\n"
     ]
    }
   ],
   "source": [
    "# mobilemasr scraper\n",
    "\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "from datetime import datetime\n",
    "\n",
    "url_template = \"https://mobilemasr.com/search?q=used+mobile&page={i}\"\n",
    "\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "}\n",
    "\n",
    "# Create CSV file and write headers\n",
    "with open('mobilemisr_phones.csv', 'w', newline='', encoding='utf-8') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow(['phone_name', 'Price', 'Seller_Name', 'Listing_URL', 'Scraped_Date'])\n",
    "\n",
    "    for i in range(1, 21):  # Loop through pages 1 to 20\n",
    "        try:\n",
    "            print(f\"Scraping page {i}...\")\n",
    "            \n",
    "            url = url_template.format(i=i)\n",
    "            response = requests.get(url, headers=headers, timeout=10)\n",
    "            \n",
    "            if response.status_code != 200:\n",
    "                print(f\"Failed to fetch page {i}. Status code: {response.status_code}\")\n",
    "                continue\n",
    "                \n",
    "            soup = BeautifulSoup(response.content, 'html.parser')\n",
    "            phones = soup.find_all('div', class_=\"product-card max-w-sm bg-white rounded-lg relative font-noto-or-Trebuchet h-[409px] group w-[140px] sm:w-[180px] md:w-[200px] my-2\")\n",
    "\n",
    "\n",
    "            for phone in phones:\n",
    "                try:\n",
    "                    # Extract phone_name\n",
    "                    phone_name_element = phone.find('div', class_=\"h-[47px] p-0 m-0\")\n",
    "                    phone_name = phone_name_element.text.strip() if phone_name_element else \"No phone_name\"\n",
    "\n",
    "                    # Extract price\n",
    "                    price_element = phone.find('p', class_=\"flex justify-between text-sm sm:text-base py-1 font-black\")\n",
    "                    price = price_element.text.strip() if price_element else \"No price\"\n",
    "\n",
    "                    # Extract seller name\n",
    "                    seller_element = phone.find('p', class_=\"text-xs font-[400] px-1\")\n",
    "                    seller_name = seller_element.text.strip() if seller_element else \"No Seller Name\"\n",
    "\n",
    "                    # Extract listing URL\n",
    "                    listing_url_element = phone.find('a')\n",
    "                    if listing_url_element and listing_url_element.get('href'):\n",
    "                        relative_url = listing_url_element['href']\n",
    "                        listing_url = \"https://mobilemasr.com\" + relative_url\n",
    "                    else:\n",
    "                        listing_url = \"No listing url\"\n",
    "\n",
    "                    # Get current date\n",
    "                    scraped_date = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "                    \n",
    "                    # Write data to CSV\n",
    "                    writer.writerow([phone_name, price, seller_name, listing_url, scraped_date])\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing a phone on page {i}: {e}\")\n",
    "                    continue\n",
    "                    \n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching page {i}: {e}\")\n",
    "            continue\n",
    "\n",
    "print(\"Scraping completed! Data saved to mobilemisr_phones.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39f9d45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e739319a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb9656f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening Noon website...\n",
      "Searching for 'used phones'...\n",
      "Waiting for search results...\n",
      "Loading more products...\n",
      "Found 15 products\n",
      "Scraped: ابل  هاتف آيفون 13 بذاكرة داخلية 128 جيجابايت وتقنية 5G مع تطبيق فيس تايم بلون ميدنايت - إصدار عالمي\n",
      "Scraped: ابل  آيفون 16 برو ماكس سعة 256 جيجابايت تيتانيوم صحراوي 5G مع فيس تايم - نسخة الشرق الأوسط\n",
      "Scraped: سامسونج جالاكسي زد فليب 7 ثنائي الشريحة ظل أزرق 12 جيجابايت 256 جيجابايت 5G - نسخة الشرق الأوسط\n",
      "Scraped: سامسونج جالاكسي S25 ألترا AI ثنائي الشريحة رمادي تيتانيوم 12 جيجابايت RAM 256 جيجابايت 5G - نسخة الشرق الأوسط\n",
      "Scraped: سامسونج جالاكسي Z فليب 7 ثنائي الشريحة أسود جت 12 جيجابايت 256 جيجابايت 5G - نسخة الشرق الأوسط\n",
      "Scraped: سامسونج Galaxy Z Flip 7 Dual SIM Jet Black 12GB 256GB 5G - International Version\n",
      "Scraped: سامسونج Galaxy Z Flip 7 Dual SIM Jet Black 12GB 512GB 5G - International Version\n",
      "Scraped: سامسونج هاتف Galaxy Z Fold 6 ثنائي الشريحة بلون فضي وذاكرة وصول عشوائي (RAM) سعة 12 جيجابايت وذاكرة تخزين داخلية 256 جيجابايت يدعم تقنية 5G مع هدية - إصدار الشرق الأوسط\n",
      "Scraped: نوكيا هاتف نوكيا 106 شريحتين 4جي اسود\n",
      "Scraped: نوكيا 106 ثنائي الشريحة 4G- أسود مع هدية سماعات Pro Airpods متوافقة مع Android iPhone باللون الأبيض\n",
      "Scraped: سامسونج جالاكسي Z فليب 7 ثنائي الشريحة كورال ريد 12 جيجابايت 256 جيجابايت 5G - نسخة الشرق الأوسط\n",
      "Scraped: سامسونج جالاكسي زد فليب 7 ثنائي الشريحة كورال ريد 12 جيجابايت 512 جيجابايت 5G - نسخة الشرق الأوسط\n",
      "Scraped: سامسونج Galaxy Z Flip 7 Dual SIM Coralred 12GB 512GB 5G - International Version\n",
      "Scraped: مارجون Case Cover For iPhone 15 Pro And 2 Screen Protectors 2024 New Pattern Aramid Carbon Fiber Phone Case Slim And Light Design MIX3\n",
      "Scraped: سامسونج جالاكسي M34 ثنائي الشريحة أزرق داكن 8 جيجابايت رام 128 جيجابايت 5G - إصدار الشرق الأوسط\n",
      "Scraping completed! Data saved to noon_used_phones.csv\n"
     ]
    }
   ],
   "source": [
    "# noon scraper\n",
    "\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "# Set up the driver\n",
    "driver = webdriver.Chrome()\n",
    "driver.maximize_window()\n",
    "\n",
    "# Create CSV file and write headers\n",
    "with open('noon_used_phones.csv', 'w', newline='', encoding='utf-8') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow(['phone_name', 'Price', 'Seller_Name', 'Listing_URL', 'Scraped_Date'])\n",
    "\n",
    "    try:\n",
    "        # Navigate to Noon website\n",
    "        print(\"Opening Noon website...\")\n",
    "        driver.get(\"https://www.noon.com/\")\n",
    "        \n",
    "        # Wait for search box and search for \"used phones\"\n",
    "        wait = WebDriverWait(driver, 15)\n",
    "        search_box = wait.until(EC.element_to_be_clickable((By.ID, \"search-input\")))\n",
    "        \n",
    "        print(\"Searching for 'used phones'...\")\n",
    "        search_box.clear()\n",
    "        search_box.send_keys(\"used phones\")\n",
    "        search_box.send_keys(Keys.RETURN)\n",
    "        \n",
    "        # Wait for search results to load\n",
    "        print(\"Waiting for search results...\")\n",
    "        time.sleep(5)\n",
    "        \n",
    "        # Scroll to load more products\n",
    "        print(\"Loading more products...\")\n",
    "        for _ in range(3):\n",
    "            driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "            time.sleep(2)\n",
    "        \n",
    "        # Get the page source after JavaScript has loaded everything\n",
    "        page_source = driver.page_source\n",
    "        \n",
    "        # Parse with BeautifulSoup\n",
    "        soup = BeautifulSoup(page_source, 'html.parser')\n",
    "        \n",
    "        # Find all product containers\n",
    "        products = soup.find_all('div' , class_ =\"PBoxLinkHandler_linkWrapper__8FlHB\")\n",
    "        \n",
    "        print(f\"Found {len(products)} products\")\n",
    "        \n",
    "        for product in products:\n",
    "            try:\n",
    "                # Extract phone name using title attribute\n",
    "                try:\n",
    "                    name_element = product.find('h2', class_ =\"ProductDetailsSection_title__JorAV\")\n",
    "                    phone_name = name_element.get('title', 'No phone name')\n",
    "                except (AttributeError, TypeError):\n",
    "                    phone_name = \"No phone name\"\n",
    "                                            \n",
    "                # Extract price\n",
    "                try:\n",
    "                    price_element = product.find('div' , class_ = \"Price_sellingPrice__HFKZf\")\n",
    "                    price = price_element.get_text(strip=True) if price_element else \"No price\"\n",
    "                except (AttributeError, TypeError):\n",
    "                    price = \"No price\"\n",
    "                \n",
    "                # Extract seller/rating\n",
    "                try:\n",
    "                    rating_element = product.find('div' , class_ = \"RatingPreviewStar_textCtr__sfsJG\")\n",
    "                    seller_name = rating_element.get_text(strip=True) if rating_element else \"No Rating\"\n",
    "                except (AttributeError, TypeError):\n",
    "                    seller_name = \"No Rating\"\n",
    "                \n",
    "                # Extract listing URL\n",
    "                try:\n",
    "                    link_element = product.find('a')\n",
    "                    listing_url = link_element.get('href')\n",
    "                    if listing_url and listing_url != 'No listing url' and not listing_url.startswith('http'):\n",
    "                        listing_url = \"https://www.noon.com\" + listing_url\n",
    "                except (AttributeError, TypeError):\n",
    "                    listing_url = \"No listing url\"\n",
    "                \n",
    "                # Get current date\n",
    "                scraped_date = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "                \n",
    "                # Write data to CSV\n",
    "                writer.writerow([phone_name, price, seller_name, listing_url, scraped_date])\n",
    "                print(f\"Scraped: {phone_name}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing a product: {e}\")\n",
    "                continue\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {str(e)}\")\n",
    "    \n",
    "    finally:\n",
    "        # Close the driver\n",
    "        driver.quit()\n",
    "\n",
    "print(\"Scraping completed! Data saved to noon_used_phones.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
